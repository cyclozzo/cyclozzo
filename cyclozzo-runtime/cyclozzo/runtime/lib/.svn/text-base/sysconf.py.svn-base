import os
import sys
import logging
import datetime
import uuid
import time
from yaml import load, dump
try:
	from yaml import CLoader as Loader
	from yaml import CDumper as Dumper
except ImportError:
	from yaml import Loader, Dumper
	
#
#	Cyclozzo configuration
#

def set_folder_rights():
	os.system('chown -R cyclozzo:cyclozzo /usr/lib/hadoop')
	os.system('chown -R cyclozzo:cyclozzo /etc/cyclozzo')
	os.system('chown -R cyclozzo:cyclozzo /var/cyclozzo')
	os.system('chown -R cyclozzo:cyclozzo /opt/hypertable')
	os.system('chown -R cyclozzo:cyclozzo /var/share/cyclozzo')
	os.system('chown -R cyclozzo:cyclozzo /var/lib/tftpboot/')

def init_cyclozzo_folders():
	os.system('rm -fr /var/cyclozzo')
	print 'SysConf: Creating /var/cyclozzo'
	os.makedirs('/var/cyclozzo/logs')
	os.makedirs('/var/cyclozzo/apps')
	os.makedirs('/var/cyclozzo/dfs')
	os.makedirs('/var/cyclozzo/hyperspace')
	if not os.path.exists('/var/share/cyclozzo/'):
		os.makedirs('/var/share/cyclozzo/')
	if not os.path.exists('/var/lib/tftpboot/i386'):
		os.makedirs('/var/lib/tftpboot/i386')
	if not os.path.exists('/var/lib/tftpboot/x86_64'):
		os.makedirs('/var/lib/tftpboot/x86_64')
	if not os.path.exists('/var/lib/tftpboot/ia64'):
		os.makedirs('/var/lib/tftpboot/ia64')
	
def init_cyclozzo_configuration_folders():
	os.system('rm -fr /etc/cyclozzo')
	print 'SysConf: Creating /etc/cyclozzo'
	os.makedirs('/etc/cyclozzo')

#
#	HyperTable services management
#

def get_hypertable():
	versions = os.listdir('/opt/hypertable/')
	max_version = [0,0,0,0]
	for v in versions:
		if v == 'current':
			continue
		parts = v.split('.')
		found_version = parts[:4]
		if len(parts) > 4:
			print 'Git revision: %s' % parts[4]
		if found_version > max_version:
			max_version = found_version
			
				
	return '/opt/hypertable/%s.%s.%s.%s/' % (max_version[0], max_version[1], max_version[2], max_version[3])

def configure_hypertable(primary = None, secondary = []):
	metadata_scheme_default = '''
<Schema>
  <AccessGroup name="default">
    <ColumnFamily>
      <Name>LogDir</Name>
    </ColumnFamily>
    <ColumnFamily>
      <Name>Files</Name>
    </ColumnFamily>
  </AccessGroup>
  <AccessGroup name="location" inMemory="true">
    <ColumnFamily>
      <Name>StartRow</Name>
      <MaxVersions>5</MaxVersions>
    </ColumnFamily>
    <ColumnFamily>
      <Name>Location</Name>
      <MaxVersions>5</MaxVersions>
    </ColumnFamily>
  </AccessGroup>
  <AccessGroup name="logging">
    <ColumnFamily>
      <Name>Event</Name>
    </ColumnFamily>
  </AccessGroup>
</Schema>

'''
	hypertable_cfg_template = '''
# Global properties
Hypertable.Request.Timeout=180000

# HDFS Broker
# Access to master HDFS
HdfsBroker.Port=38030
HdfsBroker.fs.default.name=hdfs://%s:9000
HdfsBroker.Workers=20

#Access to local hadoop instance 
#for both master and slave
DfsBroker.Host=localhost
DfsBroker.Port=38030

# Hyperspace
%s
Hyperspace.Replica.Port=38040
Hyperspace.Replica.Dir=/var/cyclozzo/hyperspace
Hyperspace.Replica.Workers=20

# Hypertable.Master
Hypertable.Master.Host=%s
Hypertable.Master.Port=38050
Hypertable.Master.Workers=20

# Hypertable.RangeServer
Hypertable.RangeServer.Port=38060

Hyperspace.KeepAlive.Interval=30000
Hyperspace.Lease.Interval=1000000
Hyperspace.GracePeriod=200000

# ThriftBroker
ThriftBroker.Port=38080
'''

	print 'SysConf: Configuring HyperTable (Common)'
	if not primary:
		print 'Please specify ip address for Cloud DS Master'
		primary = raw_input('Keep empty for default 127.0.0.1: ')
		if not primary:
			primary = '127.0.0.1'
	
	#build hyperspace replicas list
	hyperspace_cfg = 'Hyperspace.Replica.Host=%s' % primary
	for r in secondary:
		hyperspace_cfg += '\nHyperspace.Replica.Host=%s' % r
	
	hypertable_cfg = open('/etc/cyclozzo/hypertable.cfg', 'w')
	hypertable_cfg.write(hypertable_cfg_template % (primary, hyperspace_cfg, primary))
	hypertable_cfg.close()
	
	hypertable_path = get_hypertable()	
	if not os.path.exists(hypertable_path) or not os.path.isdir(hypertable_path):
		print 'SysConf: Failed to find HyperTable installation at %s' % hypertable_path
		sys.exit(-1)
	
	if not os.path.exists('/etc/cyclozzo/METADATA.xml'):
		print 'Getting METADATA'
		if os.path.exists(os.path.join(hypertable_path, 'conf', 'METADATA.xml')):
			meta_path = os.path.join(hypertable_path, 'conf', 'METADATA.xml')
		elif os.path.exists(os.path.join(hypertable_path, 'conf.backup', 'METADATA.xml')):
			meta_path = os.path.join(hypertable_path, 'conf.backup', 'METADATA.xml')
		else:
			meta_path = None
		if meta_path:
			print 'Using metadata for DS from %s' % meta_path
			if os.system('cp -f %s /etc/cyclozzo/METADATA.xml' % meta_path ) != 0:
				print 'Failed to copy!'
				sys.exit(-1)
		else:
			print 'SysConf: Generating default METADATA.xml'
			mfile = open('/etc/cyclozzo/METADATA.xml', 'w')
			mfile.write(metadata_scheme_default)
			mfile.flush()
			mfile.close()
	
	print 'SysConf: Creating symlinks'
	os.system('rm -rf %s' % os.path.join(hypertable_path, 'log'))
	os.system('rm -rf %s' % os.path.join(hypertable_path, 'run'))
	if not os.path.exists(os.path.join(hypertable_path, 'conf.backup')):
		print 'SysConf: Backup default DS conf to %s' % os.path.join(hypertable_path, 'conf.backup')
		os.system('mv %s %s' % (os.path.join(hypertable_path, 'conf'), os.path.join(hypertable_path, 'conf.backup')) )
	os.system('rm -rf %s' % os.path.join(hypertable_path, 'conf'))
	os.system('rm -rf %s' % os.path.join(hypertable_path, 'fs'))
	os.system('rm -rf %s' % os.path.join(hypertable_path, 'hyperspace'))
	os.system('ln -s /var/cyclozzo/hyperspace %s' % os.path.join(hypertable_path, 'hyperspace'))
	os.system('ln -s /var/cyclozzo/logs %s' % os.path.join(hypertable_path, 'log'))
	os.system('ln -s /var/cyclozzo/logs %s' % os.path.join(hypertable_path, 'run'))
	os.system('ln -s /etc/cyclozzo %s' % os.path.join(hypertable_path, 'conf'))

	if not os.path.exists('/etc/ld.so.conf.d/hypertable-cyclozzo.conf'):
		print 'SysConf: Updating linker path'
		ff = open('/etc/ld.so.conf.d/hypertable-cyclozzo.conf', 'w')
		ff.write('%s\n' % os.path.join(hypertable_path, 'lib'))
		ff.close()
		os.system('sudo /sbin/ldconfig')
 
	return hypertable_path

def format_ds():
	print 'SysConf: Waiting for HDFS'
	if os.system('su cyclozzo -c "/usr/bin/hadoop dfsadmin -safemode wait"') != 0:
		print 'SysConf: HDFS failed to leave safe mode.'
		sys.exit(-1)

	print 'SysConf: Formatting Hypertable  (Master)'
	from cyclozzo.runtime.lib.cmnd import run_command
	os.system('su cyclozzo -c "/usr/bin/hadoop fs -rmr /hypertable" 2>/dev/null')
	if os.system('su cyclozzo -c "/usr/bin/hadoop fs -mkdir /hypertable"') != 0:
		print 'SysConf: Failed to create dfs://hypertable'
		sys.exit(-1)
	if os.system('su cyclozzo -c "/usr/bin/hadoop fs -chmod 777 /hypertable"') != 0:
		print 'SysConf: Failed to chmod dfs:/hypertable'
		sys.exit(-1)
	
	start_dfs_broker()
	ht_path = get_hypertable()
	#if os.system('su cyclozzo -c "%s"' % os.path.join(ht_path, 'bin', 'start-hyperspace.sh') ):
	#	print 'SysConf: Failed to start Hyperspace.'
	#	sys.exit(-1)
	if os.system('su cyclozzo -c "%s"' % os.path.join(ht_path, 'bin', 'clean-database.sh') ):
		print 'SysConf: Failed to clear Datastore.'
		sys.exit(-1)
	if os.system('su cyclozzo -c "%s"' % os.path.join(ht_path, 'bin', 'clean-hyperspace.sh') ):
		print 'SysConf: Failed to clear Hyperspace.'
		sys.exit(-1)
	stop_hadoop_master()

def start_hyperspace():
	ht_path = get_hypertable()
	if os.system('su cyclozzo -c "%s"' % os.path.join(ht_path, 'bin', 'start-hyperspace.sh') ):
		print 'SysConf: Failed to start Hyperspace.'
		sys.exit(-1)	

def start_dfs_broker():
	ht_path = get_hypertable()
	if os.path.exists('/var/cyclozzo/logs/DfsBroker.hadoop.pid'):
		dfs_pid_file = open('/var/cyclozzo/logs/DfsBroker.hadoop.pid', 'r')
		dfs_pid = int(dfs_pid_file.readline().strip())
		dfs_pid_file.close()
		print 'SysConf: DFS Broker is running with pid: %d' % dfs_pid
	else:
		print 'SysConf: Starting DFS Broker'
		os.system('chown -R cyclozzo:cyclozzo /etc/cyclozzo')
		os.system('chown -R cyclozzo:cyclozzo /var/cyclozzo')
		os.system('chown -R cyclozzo:cyclozzo /opt/hypertable')
		if os.system('su cyclozzo -c "%s/bin/start-dfsbroker.sh hadoop"' % ht_path) != 0:
			print 'SysConf: Failed to start DFS Broker'
			sys.exit(-1)

def start_hypertable_thriftbroker():
	print 'SysConf: Starting Thriftbroker'
	ht_path = get_hypertable()
	if os.system('su cyclozzo -c "%s/bin/start-thriftbroker.sh"' % ht_path) != 0:
		print 'SysConf: Failed to start DS Thriftbroker'
		sys.exit(-1)
		
def start_hypertable_master():
	print 'SysConf: Starting HyperTable (Master)'
	ht_path = get_hypertable()
	if os.system('su cyclozzo -c "%s/bin/start-master.sh"' % ht_path) != 0:
		print 'SysConf: Failed to start DS Master'
		sys.exit(-1)

def start_hypertable_slave():
	print 'SysConf: Starting HyperTable (Slave)'
	ht_path = get_hypertable()
	if os.system('su cyclozzo -c "%s/bin/start-rangeserver.sh"' % ht_path) != 0:
		print 'SysConf: Failed to start DS RangeServer'
		sys.exit(-1)

def stop_hypertable():
	print 'SysConf: Stopping HyperTable (Master)'
	os.system('su cyclozzo -c "%s/bin/stop-servers.sh"' % get_hypertable())
	
#
#	Hadoop services management
#

def configure_hadoop(primary = None, secondary = []):
	hdfs_site = '''
<configuration>
	<property>
		<name>dfs.name.dir</name>
		<value>/var/cyclozzo/dfs/name</value>
	</property>
	<property>
		<name>dfs.data.dir</name>
		<value>/var/cyclozzo/dfs/data</value>
	</property>
</configuration>
'''
	core_site = '''
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://%s:9000</value>
	</property>
</configuration>
'''
	print 'SysConf: Configuring HDFS (Common)'
	hadoop_env = open('/etc/cyclozzo/hadoop-env.sh', 'w')
	hadoop_env.write('export JAVA_HOME=/usr/lib/jvm/java-6-sun\n')
	hadoop_env.close()
	
	hdfs_site_file = open('/etc/cyclozzo/hdfs-site.xml', 'w')
	hdfs_site_file.write(hdfs_site)
	hdfs_site_file.close()
	
	if not primary:
		print 'Please specify ip address for System Cloud DFS Master'
		primary = raw_input('Keep empty for default 127.0.0.1: ')
		if not primary:
			primary = '127.0.0.1'
	
	core_site_file = open('/etc/cyclozzo/core-site.xml', 'w')
	core_site_file.write(core_site % primary)
	core_site_file.close()
	
	masters = open('/etc/cyclozzo/masters', 'w')
	masters.write(primary +'\n')
	masters.close()
	
	slaves = open('/etc/cyclozzo/slaves', 'w')
	slaves.write(primary +'\n')
	for s in secondary:
		slaves.write(s + '\n')
	slaves.close()
	
	print 'Creating links for DFS to /var/cyclozzo'
	from cyclozzo.runtime.lib.cmnd import run_command
	rc, out = run_command(['rm', '-f' , '/usr/lib/hadoop/logs'])
	if rc != 0:
		print 'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)
	rc, out = run_command(['rm', '-f' , '/usr/lib/hadoop/pids'])
	if rc != 0:
		print 'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)
	rc, out = run_command(['rm', '-f' , '/usr/lib/hadoop/conf'])
	if rc != 0:
		print'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)
	
	rc, out = run_command(['ln', '-s' , '/var/cyclozzo/logs/', '/usr/lib/hadoop/logs'])
	if rc != 0:
		print 'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)
	rc, out = run_command(['ln', '-s' , '/var/cyclozzo/logs/', '/usr/lib/hadoop/pids'])
	if rc != 0:
		print 'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)
	rc, out = run_command(['ln', '-s' , '/etc/cyclozzo/', '/usr/lib/hadoop/conf'])
	if rc != 0:
		print 'Failed to configure DFS, code = %s : %s' % (rc, out)
		sys.exit(-1)

def start_hadoop_master():
	from cyclozzo.runtime.lib.cmnd import run_command
	set_folder_rights()
	
	#start slave services too
	start_hadoop_slave()
	
	print 'SysConf: Starting HDFS (NameNode)'
	rc = os.system('su cyclozzo -c "/usr/lib/hadoop/bin/hadoop-daemon.sh --config /etc/cyclozzo start namenode"')
	if rc != 0:
		print 'Failed to start NameNode, code = %s' % rc
		sys.exit(-1)

	name_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-namenode.pid'
	if os.path.exists(name_pid_path):
		name_pid_file = open(name_pid_path, 'r')
		name_pid = int(name_pid_file.readline().strip())
		name_pid_file.close()
		print 'NameNode service is running with pid: %d' % name_pid
	else:
		print 'No pidfile found at %s' % name_pid_path
		sys.exit(-1)
		
		
def start_hadoop_slave():
	print 'SysConf: Starting HDFS (DataNode)'
	if os.system('su cyclozzo -c "/usr/lib/hadoop/bin/hadoop-daemon.sh --config /etc/cyclozzo start datanode"') != 0:
		print 'Failed to start DataNode'
		sys.exit(-1)

	data_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-datanode.pid'
	if os.path.exists(data_pid_path):
		data_pid_file = open(data_pid_path, 'r')
		data_pid = int(data_pid_file.readline().strip())
		data_pid_file.close()
		print 'DataNode service is running with pid: %d' % data_pid
	else:
		print 'No pidfile found at %s' % data_pid_path
		sys.exit(-1)

def clean_pids():
	print 'Sysconf: Checking for orphaned pid files and cleaning it'
	datanode_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-datanode.pid'
	namenode_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-namenode.pid'
	dfsbroker_pid_path = '/var/cyclozzo/logs/DfsBroker.hadoop.pid'
	rangeserver_pid_path = '/var/cyclozzo/logs/Hypertable.RangeServer.pid'
	hyperspace_pid_path = '/var/cyclozzo/logs/Hyperspace.pid'
	thriftbroker_pid_path = '/var/cyclozzo/logs/ThriftBroker.pid'
	hypertable_master_pid_path = '/var/cyclozzo/logs/Hypertable.Master.pid'
	

	if os.path.exists(datanode_pid_path):
		datanode_pid_file = open(datanode_pid_path, 'r')
		datanode_pid = int(datanode_pid_file.readline().strip())
		datanode_pid_file.close()
		datanode_pid_proc_path = '/proc/%s' % datanode_pid
		if os.path.exists(datanode_pid_proc_path):
			print 'DataNode service is running with pid: %d. Pid cannot be cleaned.' % datanode_pid
		else:
			os.system('rm -rf %s' % datanode_pid_path)
			print 'DataNode pid file cleaned'
	if os.path.exists(namenode_pid_path):
                namenode_pid_file = open(namenode_pid_path, 'r')
                namenode_pid = int(namenode_pid_file.readline().strip())
                namenode_pid_file.close()
                namenode_pid_proc_path = '/proc/%s' % namenode_pid
                if os.path.exists(namenode_pid_proc_path):
                        print 'NameNode service is running with pid: %d. Pid cannot be cleaned.' % namenode_pid
                else:
                        os.system('rm -rf %s' % namenode_pid_path)
			print 'NameNode pid file cleaned'
	if os.path.exists(dfsbroker_pid_path):
                dfsbroker_pid_file = open(dfsbroker_pid_path, 'r')
                dfsbroker_pid = int(dfsbroker_pid_file.readline().strip())
                dfsbroker_pid_file.close()
                dfsbroker_pid_proc_path = '/proc/%s' % dfsbroker_pid
                if os.path.exists(dfsbroker_pid_proc_path):
                        print 'DfsBroker is running with pid: %d. Pid cannot be cleaned.' % dfsbroker_pid
                else:
                        os.system('rm -rf %s' % dfsbroker_pid_path)
			print 'DfsBroker pid file cleaned'	
	if os.path.exists(rangeserver_pid_path):
                rangeserver_pid_file = open(rangeserver_pid_path, 'r')
                rangeserver_pid = int(rangeserver_pid_file.readline().strip())
                rangeserver_pid_file.close()
                rangeserver_pid_proc_path = '/proc/%s' % rangeserver_pid
                if os.path.exists(rangeserver_pid_proc_path):
                        print 'RangeServer is running with pid: %d. Pid cannot be cleaned.' % rangeserver_pid
                else:
                        os.system('rm -rf %s' % rangeserver_pid_path)
			print 'RangeServer pid file cleaned'
	if os.path.exists(hyperspace_pid_path):
                hyperspace_pid_file = open(hyperspace_pid_path, 'r')
                hyperspace_pid = int(hyperspace_pid_file.readline().strip())
                hyperspace_pid_file.close()
                hyperspace_pid_proc_path = '/proc/%s' % hyperspace_pid
                if os.path.exists(hyperspace_pid_proc_path):
                        print 'Hyperspace is running with pid: %d. Pid cannot be cleaned.' % hyperspace_pid
                else:
                        os.system('rm -rf %s' % hyperspace_pid_path)
			print 'HyperSpace pid file cleaned'
	if os.path.exists(thriftbroker_pid_path):
                thriftbroker_pid_file = open(thriftbroker_pid_path, 'r')
                thriftbroker_pid = int(thriftbroker_pid_file.readline().strip())
                thriftbroker_pid_file.close()
                thriftbroker_pid_proc_path = '/proc/%s' % thriftbroker_pid
                if os.path.exists(thriftbroker_pid_proc_path):
                        print 'ThriftBroker is running with pid: %d. Pid cannot be cleaned.' % thriftbroker_pid
                else:
                        os.system('rm -rf %s' % thriftbroker_pid_path)
			print 'ThriftBroken pid file cleaned'
	if os.path.exists(hypertable_master_pid_path):
                hypertable_master_pid_file = open(hypertable_master_pid_path, 'r')
                hypertable_master_pid = int(hypertable_master_pid_file.readline().strip())
                hypertable_master_pid_file.close()
                hypertable_master_pid_proc_path = '/proc/%s' % hypertable_master_pid
                if os.path.exists(hypertable_master_pid_proc_path):
                        print 'HypertableMaster is running with pid: %d. Pid cannot be cleaned.' % hypertable_master_pid
                else:
                        os.system('rm -rf %s' % hypertable_master_pid_path)
                        print 'HypertableMaster pid file cleaned'	

def stop_hadoop_master():
	stop_hadoop_slave()
	print 'SysConf: Stopping HDFS (NameNode)'
	if os.system('su cyclozzo -c "/usr/lib/hadoop/bin/hadoop-daemon.sh --config /etc/cyclozzo/ stop namenode"') == 0:
		name_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-namenode.pid'
		os.system('rm -rf %s' % name_pid_path)
		print 'Removing NameNode PID file: %s' % name_pid_path
	
	#os.system('su cyclozzo -c "/usr/lib/hadoop/bin/hadoop-daemon.sh --config /etc/cyclozzo/ stop datanode"')
	
def stop_hadoop_slave():
	print 'SysConf: Stopping HDFS (DataNode)'
	if os.system('su cyclozzo -c "/usr/lib/hadoop/bin/hadoop-daemon.sh --config /etc/cyclozzo/ stop datanode"') == 0:
		data_pid_path = '/var/cyclozzo/logs/hadoop-cyclozzo-datanode.pid'
                os.system('rm -rf %s' % data_pid_path)
                print 'Removing DataNode PID file: %s' % data_pid_path
def format_dfs():
	set_folder_rights()
	print 'SysConf: Formating HDFS'
	os.system('rm -fr /var/cyclozzo/dfs/*')
	os.system('rm -fr /var/cyclozzo/dfs/name/*')
	format = open('/tmp/format_namenode.sh', 'w')
	format.write('echo Y | /usr/bin/hadoop namenode -format\n')
	format.close()

	from cyclozzo.runtime.lib.cmnd import run_command
	print 'Formating DFS NameNode and DataNode'

	if os.system('su cyclozzo -c "sh /tmp/format_namenode.sh"') != 0:
			print 'Failed to format DFS NameNode'
			sys.exit(-1)
	if os.system('su cyclozzo -c "/usr/bin/hadoop datanode -format"') != 0:
			print 'Failed to format DFS DataNode'
			sys.exit(-1)
